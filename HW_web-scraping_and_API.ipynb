{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежими новостям на habr.com/ru/all/.\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы).\n",
    "\n",
    "В итоге должен формироваться датафрейм вида: <дата> - <заголовок> - <ссылка>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL = 'https://habr.com/ru/search/'\n",
    "KEYWORDS = ['python', 'парсинг']\n",
    "\n",
    "def get_all_links(url, query, pages):\n",
    "    link_list = []\n",
    "    for q in query:\n",
    "        params = {\n",
    "            'q': q,\n",
    "            'target_type': 'posts'\n",
    "        }\n",
    "        headers = {\n",
    "            'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/12.1.2 Safari/605.1.15'\n",
    "        }\n",
    "        for i in range(1, pages):\n",
    "            req = requests.get(URL + 'page' + str(i), params=params, headers=headers)\n",
    "            time.sleep(0.03)\n",
    "            soup = BeautifulSoup(req.text, 'html.parser')\n",
    "            # добираемся до блоков с новостями\n",
    "            news_blocks = soup.find_all('article', class_=\"post post_preview\")\n",
    "            # добираемся до текста со ссылкой\n",
    "            articles_intro = list(map(lambda x: x.find('h2', class_='post__title'), news_blocks))\n",
    "            # добираемся до ссылок\n",
    "            link_list += list(map(lambda x: x.find('a', class_=\"post__title_link\").get('href'), articles_intro))\n",
    "\n",
    "    return link_list\n",
    "\n",
    "all_links = get_all_links(URL, KEYWORDS, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>\\nВышел Python 2.7.18, последний релиз ветки P...</td>\n",
       "      <td>https://habr.com/ru/news/t/498364/</td>\n",
       "      <td>\\n\\r\\n20 апреля 2020 года, спустя почти десять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-12-04</td>\n",
       "      <td>\\nPython как компилируемый статически типизиро...</td>\n",
       "      <td>https://habr.com/ru/news/t/531402/</td>\n",
       "      <td>\\nПо данным широко известного в узких кругах T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>\\nВ начале этого года Python сместил Java и ст...</td>\n",
       "      <td>https://habr.com/ru/company/itsumma/news/t/490...</td>\n",
       "      <td>\\nСогласно отчету RedMonk за январь 2020 года,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-03</td>\n",
       "      <td>\\nВышла версия 0.0.2 snakeware — дистрибутива ...</td>\n",
       "      <td>https://habr.com/ru/news/t/505096/</td>\n",
       "      <td>\\n\\n\\r\\n31 мая 2020 года разработчик Джош Мур ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>\\nСоздатель Python Гвидо ван Россум выходит на...</td>\n",
       "      <td>https://habr.com/ru/news/t/527858/</td>\n",
       "      <td>\\n\\n\\r\\nСоздатель языка программирования Pytho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-12</td>\n",
       "      <td>\\nPHP-библиотеки для e-commerce: работа с АТОЛ...</td>\n",
       "      <td>https://habr.com/ru/company/lamoda/blog/466039/</td>\n",
       "      <td>\\nПривет, меня зовут Павел Савельев, я руковод...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>\\nИспользуйте парсинг вместо контроля типов\\n</td>\n",
       "      <td>https://habr.com/ru/company/vdsina/blog/537398/</td>\n",
       "      <td>\\n\\n\\r\\nВ 2019 году была написана потрясающая ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-04-21</td>\n",
       "      <td>\\nОсновы парсинга с помощью Python+lxml\\n</td>\n",
       "      <td>https://habr.com/ru/post/220125/</td>\n",
       "      <td>\\nДобрый день, уважаемые читатели.\\r\\nВ сегодн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-03-09</td>\n",
       "      <td>\\nПростая библиотека для парсинга HTML\\n</td>\n",
       "      <td>https://habr.com/ru/post/115135/</td>\n",
       "      <td>\\nНедавно зарелизил Leaf, это небольшая библио...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-03-03</td>\n",
       "      <td>\\nPomp — метафреймворк для парсинга сайтов\\n</td>\n",
       "      <td>https://habr.com/ru/post/278445/</td>\n",
       "      <td>\\nС поддержкой asyncio и вдохновленный Scrapy....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                              title  \\\n",
       "0   2020-04-21  \\nВышел Python 2.7.18, последний релиз ветки P...   \n",
       "0   2020-12-04  \\nPython как компилируемый статически типизиро...   \n",
       "0   2020-03-03  \\nВ начале этого года Python сместил Java и ст...   \n",
       "0   2020-06-03  \\nВышла версия 0.0.2 snakeware — дистрибутива ...   \n",
       "0   2020-11-13  \\nСоздатель Python Гвидо ван Россум выходит на...   \n",
       "..         ...                                                ...   \n",
       "0   2019-09-12  \\nPHP-библиотеки для e-commerce: работа с АТОЛ...   \n",
       "0   2021-01-15      \\nИспользуйте парсинг вместо контроля типов\\n   \n",
       "0   2014-04-21          \\nОсновы парсинга с помощью Python+lxml\\n   \n",
       "0   2011-03-09           \\nПростая библиотека для парсинга HTML\\n   \n",
       "0   2016-03-03       \\nPomp — метафреймворк для парсинга сайтов\\n   \n",
       "\n",
       "                                                 link  \\\n",
       "0                  https://habr.com/ru/news/t/498364/   \n",
       "0                  https://habr.com/ru/news/t/531402/   \n",
       "0   https://habr.com/ru/company/itsumma/news/t/490...   \n",
       "0                  https://habr.com/ru/news/t/505096/   \n",
       "0                  https://habr.com/ru/news/t/527858/   \n",
       "..                                                ...   \n",
       "0     https://habr.com/ru/company/lamoda/blog/466039/   \n",
       "0     https://habr.com/ru/company/vdsina/blog/537398/   \n",
       "0                    https://habr.com/ru/post/220125/   \n",
       "0                    https://habr.com/ru/post/115135/   \n",
       "0                    https://habr.com/ru/post/278445/   \n",
       "\n",
       "                                                 text  \n",
       "0   \\n\\r\\n20 апреля 2020 года, спустя почти десять...  \n",
       "0   \\nПо данным широко известного в узких кругах T...  \n",
       "0   \\nСогласно отчету RedMonk за январь 2020 года,...  \n",
       "0   \\n\\n\\r\\n31 мая 2020 года разработчик Джош Мур ...  \n",
       "0   \\n\\n\\r\\nСоздатель языка программирования Pytho...  \n",
       "..                                                ...  \n",
       "0   \\nПривет, меня зовут Павел Савельев, я руковод...  \n",
       "0   \\n\\n\\r\\nВ 2019 году была написана потрясающая ...  \n",
       "0   \\nДобрый день, уважаемые читатели.\\r\\nВ сегодн...  \n",
       "0   \\nНедавно зарелизил Leaf, это небольшая библио...  \n",
       "0   \\nС поддержкой asyncio и вдохновленный Scrapy....  \n",
       "\n",
       "[160 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_habr_news(links):\n",
    "    habr_news = pd.DataFrame()\n",
    "    for link in all_links:\n",
    "        soup = BeautifulSoup(requests.get(link).text)\n",
    "        date = pd.to_datetime(soup.find('span', class_='post__time').get('data-time_published'), dayfirst=True).date()\n",
    "        title = soup.find('h1', class_='post__title post__title_full').text\n",
    "        text = soup.find('div', class_='post__body post__body_full').text\n",
    "        row = {'date': date, 'title': title, 'link': link, 'text': text}\n",
    "        habr_news = pd.concat([habr_news, pd.DataFrame([row])])  \n",
    "    return habr_news\n",
    "\n",
    "habr_news = get_habr_news(all_links)\n",
    "habr_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса Avast Hack Ckeck. Список email-ов задаем переменной в начале кода:\n",
    "\n",
    "EMAIL = [xxx@x.ru, yyy@y.com]\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: <почта> - <дата утечки> - <источник утечки> - <описание утечки>\n",
    "\n",
    "Подсказка: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "HEADERS = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:85.0) Gecko/20100101 Firefox/85.0',\n",
    "\n",
    "    'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "    'Vaar-Version': '0',\n",
    "    'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
    "    'Vaar-Header-App-Build-Version': '1.0.0',\n",
    "\n",
    "    'Accept': 'application/json, text/plain, */*',\n",
    "    'Content-Type': 'application/json;charset=UTF-8',\n",
    "    'Host': 'identityprotection.avast.com',\n",
    "    'Origin': 'https://www.avast.com',\n",
    "    'Referer': 'https://www.avast.com/hackcheck/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>date</th>\n",
       "      <th>site</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2019-03-28T00:00:00Z</td>\n",
       "      <td>verifications.io</td>\n",
       "      <td>Big data e-mail verification platform verifica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2020-05-21T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>At some time in 2020, the Russian social netwo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>parapa.mail.ru</td>\n",
       "      <td>In July and August 2016, two criminals execute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-29T00:00:00Z</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2017-02-14T00:00:00Z</td>\n",
       "      <td>cfire.mail.ru</td>\n",
       "      <td>In July and August of 2016, two criminals carr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2017-01-31T00:00:00Z</td>\n",
       "      <td>cdprojektred.com</td>\n",
       "      <td>In March 2016, CDProjektRed.com.com's forum da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxx@x.ru</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2020-01-03T00:00:00Z</td>\n",
       "      <td>azcentral.com</td>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2020-05-28T00:00:00Z</td>\n",
       "      <td>wishbone.io</td>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-11-04T00:00:00Z</td>\n",
       "      <td>myheritage.com</td>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2021-02-11T00:00:00Z</td>\n",
       "      <td>forums.vkmonline.com</td>\n",
       "      <td>At an unconfirmed date, the Russian-language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2019-06-13T00:00:00Z</td>\n",
       "      <td>canva.com</td>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-24T00:00:00Z</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>linkedin.com</td>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-03-01T00:00:00Z</td>\n",
       "      <td>rayli.com.cn</td>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2019-10-17T00:00:00Z</td>\n",
       "      <td>zynga.com</td>\n",
       "      <td>In September 2019, the game developer Zynga wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-21T00:00:00Z</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2018-02-18T00:00:00Z</td>\n",
       "      <td>netlog.com</td>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-03-15T00:00:00Z</td>\n",
       "      <td>globalreach.eu</td>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016-10-23T00:00:00Z</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017-03-24T00:00:00Z</td>\n",
       "      <td>youku.com</td>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       email                  date                  site  \\\n",
       "0   xxx@x.ru  2019-03-28T00:00:00Z      verifications.io   \n",
       "0   xxx@x.ru  2020-05-21T00:00:00Z                vk.com   \n",
       "0   xxx@x.ru  2017-02-14T00:00:00Z        parapa.mail.ru   \n",
       "0   xxx@x.ru  2016-10-29T00:00:00Z                vk.com   \n",
       "0   xxx@x.ru  2016-10-21T00:00:00Z             adobe.com   \n",
       "0   xxx@x.ru  2017-02-14T00:00:00Z         cfire.mail.ru   \n",
       "0   xxx@x.ru  2017-01-31T00:00:00Z      cdprojektred.com   \n",
       "0   xxx@x.ru  2016-10-23T00:00:00Z             imesh.com   \n",
       "0  yyy@y.com  2020-01-03T00:00:00Z         azcentral.com   \n",
       "0  yyy@y.com  2020-05-28T00:00:00Z           wishbone.io   \n",
       "0  yyy@y.com  2017-11-04T00:00:00Z        myheritage.com   \n",
       "0  yyy@y.com  2021-02-11T00:00:00Z  forums.vkmonline.com   \n",
       "0  yyy@y.com  2019-06-13T00:00:00Z             canva.com   \n",
       "0  yyy@y.com  2016-10-24T00:00:00Z           dropbox.com   \n",
       "0  yyy@y.com  2016-10-21T00:00:00Z          linkedin.com   \n",
       "0  yyy@y.com  2017-03-01T00:00:00Z          rayli.com.cn   \n",
       "0  yyy@y.com  2019-10-17T00:00:00Z             zynga.com   \n",
       "0  yyy@y.com  2016-10-21T00:00:00Z             adobe.com   \n",
       "0  yyy@y.com  2018-02-18T00:00:00Z            netlog.com   \n",
       "0  yyy@y.com  2017-03-15T00:00:00Z        globalreach.eu   \n",
       "0  yyy@y.com  2016-10-23T00:00:00Z             imesh.com   \n",
       "0  yyy@y.com  2017-03-24T00:00:00Z             youku.com   \n",
       "\n",
       "                                         description  \n",
       "0  Big data e-mail verification platform verifica...  \n",
       "0  At some time in 2020, the Russian social netwo...  \n",
       "0  In July and August 2016, two criminals execute...  \n",
       "0  Popular Russian social networking platform VKo...  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  In July and August of 2016, two criminals carr...  \n",
       "0  In March 2016, CDProjektRed.com.com's forum da...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  At an unconfirmed date, online Arizona newspap...  \n",
       "0  In January 2020, the online poll website Wishb...  \n",
       "0  In October 2017, a customer database belonging...  \n",
       "0  At an unconfirmed date, the Russian-language m...  \n",
       "0  In May 2019, graphic-design site Canva's datab...  \n",
       "0  Cloud storage company Dropbox suffered a major...  \n",
       "0  In 2012, online professional networking platfo...  \n",
       "0  On an unconfirmed date, Chinese gossip site Ra...  \n",
       "0  In September 2019, the game developer Zynga wa...  \n",
       "0  In October of 2013, criminals penetrated Adobe...  \n",
       "0  Netlog (formerly known as Facebox and Bingbox)...  \n",
       "0  In 2016, Global Reach Technology's database wa...  \n",
       "0  In June 2016, a cache of over 51 million user ...  \n",
       "0  Youku is a large Chinese video content company...  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMAILS = ['xxx@x.ru', 'yyy@y.com']\n",
    "\n",
    "def data_from_json(json_file, mail):\n",
    "    df_full = pd.DataFrame()\n",
    "    for id_, data in json_file['breaches'].items():\n",
    "        row = {}\n",
    "        row['email'] = mail\n",
    "        row['date'] = data['publishDate']\n",
    "        row['site'] = data['site']\n",
    "        row['description'] = data['description']\n",
    "        df_full = pd.concat([df_full, pd.DataFrame([row])])\n",
    "    return df_full\n",
    "\n",
    "def check_emails(emails):\n",
    "    checked_emails = pd.DataFrame()\n",
    "    for email in emails:\n",
    "        PAYLOAD = {\n",
    "            \"emailAddresses\":[email]\n",
    "        }\n",
    "        r = requests.post(URL, headers=HEADERS, json=PAYLOAD)\n",
    "        row = data_from_json(r.json(), email)\n",
    "        checked_emails = pd.concat([checked_emails, row])\n",
    "    return checked_emails\n",
    "\n",
    "check_emails(EMAILS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
