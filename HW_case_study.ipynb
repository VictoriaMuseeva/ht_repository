{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вернемся к набору данных о видеоиграх.\n",
    "\n",
    "Ответьте на следующие вопросы:\n",
    "\n",
    "    1) Как критики относятся к спортивным играм?\n",
    "    2) Критикам нравятся больше игры на PC или на PS4?\n",
    "    3) Критикам больше нравятся стрелялки или стратегии?\n",
    "\n",
    "Для каждого вопроса:\n",
    "\n",
    "- сформулируйте нулевую и альтернативную гипотезы;\n",
    "- выберите пороговый уровень статистической значимости;\n",
    "- опишите полученные результаты статистического теста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>VGChartz_Score</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>Total_Shipped</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>PAL_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Year</th>\n",
       "      <th>status</th>\n",
       "      <th>Vgchartzscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>55792.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6536.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>1827.000000</td>\n",
       "      <td>19415.000000</td>\n",
       "      <td>12964.000000</td>\n",
       "      <td>13189.000000</td>\n",
       "      <td>7043.000000</td>\n",
       "      <td>15522.000000</td>\n",
       "      <td>54813.000000</td>\n",
       "      <td>55792.0</td>\n",
       "      <td>799.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27896.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.213709</td>\n",
       "      <td>8.253433</td>\n",
       "      <td>1.887258</td>\n",
       "      <td>0.365503</td>\n",
       "      <td>0.275541</td>\n",
       "      <td>0.155263</td>\n",
       "      <td>0.110402</td>\n",
       "      <td>0.044719</td>\n",
       "      <td>2005.659095</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.425907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16105.907446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.454079</td>\n",
       "      <td>1.401489</td>\n",
       "      <td>4.195693</td>\n",
       "      <td>0.833022</td>\n",
       "      <td>0.512809</td>\n",
       "      <td>0.399257</td>\n",
       "      <td>0.184673</td>\n",
       "      <td>0.129554</td>\n",
       "      <td>8.355585</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.384226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>13948.750000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>27896.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41844.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.300000</td>\n",
       "      <td>9.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>55792.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>82.860000</td>\n",
       "      <td>20.320000</td>\n",
       "      <td>9.760000</td>\n",
       "      <td>9.850000</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>3.120000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Rank  VGChartz_Score  Critic_Score  User_Score  Total_Shipped  \\\n",
       "count  55792.000000             0.0   6536.000000  335.000000    1827.000000   \n",
       "mean   27896.500000             NaN      7.213709    8.253433       1.887258   \n",
       "std    16105.907446             NaN      1.454079    1.401489       4.195693   \n",
       "min        1.000000             NaN      1.000000    2.000000       0.030000   \n",
       "25%    13948.750000             NaN      6.400000    7.800000       0.200000   \n",
       "50%    27896.500000             NaN      7.500000    8.500000       0.590000   \n",
       "75%    41844.250000             NaN      8.300000    9.100000       1.800000   \n",
       "max    55792.000000             NaN     10.000000   10.000000      82.860000   \n",
       "\n",
       "       Global_Sales      NA_Sales     PAL_Sales     JP_Sales   Other_Sales  \\\n",
       "count  19415.000000  12964.000000  13189.000000  7043.000000  15522.000000   \n",
       "mean       0.365503      0.275541      0.155263     0.110402      0.044719   \n",
       "std        0.833022      0.512809      0.399257     0.184673      0.129554   \n",
       "min        0.000000      0.000000      0.000000     0.000000      0.000000   \n",
       "25%        0.030000      0.050000      0.010000     0.020000      0.000000   \n",
       "50%        0.120000      0.120000      0.040000     0.050000      0.010000   \n",
       "75%        0.360000      0.290000      0.140000     0.120000      0.040000   \n",
       "max       20.320000      9.760000      9.850000     2.690000      3.120000   \n",
       "\n",
       "               Year   status  Vgchartzscore  \n",
       "count  54813.000000  55792.0     799.000000  \n",
       "mean    2005.659095      1.0       7.425907  \n",
       "std        8.355585      0.0       1.384226  \n",
       "min     1970.000000      1.0       2.600000  \n",
       "25%     2000.000000      1.0       6.800000  \n",
       "50%     2008.000000      1.0       7.800000  \n",
       "75%     2011.000000      1.0       8.500000  \n",
       "max     2020.000000      1.0       9.600000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('video_games_sales.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Как критики относятся к спортивным играм? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H0: средняя удовлетворенность критиков спортивными играми <= 7 баллов из 10\n",
    "- H1: средняя удовлетворенность критиков спортивными играми составляет более 7 баллов из 10 \n",
    "\n",
    "За alpha будем принимать 0.05\n",
    "\n",
    "Сравниваем значение по выборке с константой, поэтому нужен One Sample T-Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.291424418604655\n",
      "Statistics=5.197, pvalue=0.000\n",
      "Отвергаем нулевую гипотезу, среднее больше 7 (критикам нравятся спортивные игры)\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "data_score = data[data.Genre == 'Sports'].Critic_Score.dropna()\n",
    "stat, pvalue = st.ttest_1samp(data_score, 7, alternative='greater')\n",
    "\n",
    "print(data[data.Genre == 'Sports'].Critic_Score.mean())\n",
    "print('Statistics=%.3f, pvalue=%.3f' % (stat, pvalue))\n",
    "\n",
    "if pvalue < alpha: \n",
    "    print('Отвергаем нулевую гипотезу, среднее больше 7 (критикам нравятся спортивные игры)')\n",
    "else:\n",
    "    print('Не отвергаем нулевую гипотезу, критики не высоко оценивают спортивные игры')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: в целом, критики достаточно высоко оценивают спортивные игры (выше 7 баллов из 10)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Критикам нравятся больше игры на PC или на PS4?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H0: средняя удовлетворенность критиков играми на PC и на PS4 одинаковая  \n",
    "- H1: средняя удовлетворенность критиков играми на PC и на PS4 различается\n",
    "\n",
    "За alpha будем принимать 0.05\n",
    "\n",
    "Сравниваем две независимые выборки, нужен двухвыборочный двухсторонний критерий, будем использовать Welch's Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя оценка критиков для платформы PC: 7.54\n",
      "Средняя оценка критиков для платформы PS4: 7.9\n",
      "Statistics=-2.739, pvalue=0.007\n",
      "Отвергаем нулевую гипотезу, удовлетворенность критиков играми на PC и на PS4 различается\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "stat, pvalue = st.ttest_ind(data[data.Platform == 'PC'].Critic_Score, data[data.Platform == 'PS4'].Critic_Score, nan_policy='omit', equal_var=False)\n",
    "\n",
    "print('Средняя оценка критиков для платформы PC:', round(data[data.Platform == 'PC'].Critic_Score.mean(), 2))\n",
    "print('Средняя оценка критиков для платформы PS4:', round(data[data.Platform == 'PS4'].Critic_Score.mean(), 2))\n",
    "print('Statistics=%.3f, pvalue=%.3f' % (stat, pvalue))\n",
    "\n",
    "if pvalue < alpha: \n",
    "    print('Отвергаем нулевую гипотезу, удовлетворенность критиков играми на PC и на PS4 различается')\n",
    "else:\n",
    "    print('Не отвергаем нулевую гипотезу, критики одиково относятся к играм на PC и PS4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: разница между средними оценками платформ статистически значима, следовательно, критики выше оценивают игры на PS4, чем на PC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Критикам больше нравятся стрелялки или стратегии?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- H0: средняя удовлетворенность критиков стрелялками и стратегиями одинаковая\n",
    "- H1: средняя удовлетворенность критиков стрелялками и стратегиями различается\n",
    "\n",
    "За alpha будем принимать 0.05\n",
    "\n",
    "Сравниваем две независимые выборки, нужен двухвыборочный двухсторонний критерий, будем использовать Welch's Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя оценка критиков для Shooter: 7.29\n",
      "Средняя оценка критиков для Strategy: 7.43\n",
      "Statistics=-1.607, pvalue=0.108\n",
      "Не отвергаем нулевую гипотезу, критики одиково относятся к стрелялкам и стратегиям\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "stat, pvalue = st.ttest_ind(data[data.Genre == 'Shooter'].Critic_Score, data[data.Genre == 'Strategy'].Critic_Score, nan_policy='omit', equal_var=False)\n",
    "\n",
    "print('Средняя оценка критиков для Shooter:', round(data[data.Genre == 'Shooter'].Critic_Score.mean(), 2))\n",
    "print('Средняя оценка критиков для Strategy:', round(data[data.Genre == 'Strategy'].Critic_Score.mean(), 2))\n",
    "print('Statistics=%.3f, pvalue=%.3f' % (stat, pvalue))\n",
    "\n",
    "if pvalue < alpha: \n",
    "    print('Отвергаем нулевую гипотезу, удовлетворенность критиков стрелялками или стратегиями различается')\n",
    "else:\n",
    "    print('Не отвергаем нулевую гипотезу, критики одиково относятся к стрелялкам и стратегиям')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: разница между средними оценками игр статистически не значима, следовательно, в целом, критики одиково оценивают игры-стрелялки и игры-стратегии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте базовую модель логистической регрессии для классификации текстовых сообщений по признаку спама. Для этого:\n",
    "1) Приведите весь текст к нижнему регистру;<br>\n",
    "2) Удалите мусорные символы;<br>\n",
    "3) Удалите стоп-слова;<br>\n",
    "4) Приведите все слова к нормальной форме;<br>\n",
    "5) Преобразуйте все сообщения в вектора TF-IDF.\n",
    "Можете поэкспериментировать с параметрами TfidfVectorizer;<br>\n",
    "6) Разделите данные на тестовые и тренировочные в соотношении 30/70, укажите random_state=42. Используйте train_test_split;<br>\n",
    "7) Постройте модель логистической регрессии, укажите random_state=42, оцените ее точность на тестовых данных;<br>\n",
    "8) Опишите результаты при помощи confusion_matrix;<br>\n",
    "9) Постройте датафрейм, который будет содержать все исходные тексты сообщений, классифицированные неправильно (с указанием фактического и предсказанного)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, £1.50 to rcv\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_spam = pd.read_csv('spam.csv')\n",
    "data_spam.Message[5] # здесь и далее в качестве проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Приведем  весь текст к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"freemsg hey there darling it's been 3 week's now and no word back! i'd like some fun you up for it still? tb ok! xxx std chgs to send, £1.50 to rcv\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_lower_case = [mess.lower() for mess in data_spam.Message]\n",
    "messages_lower_case[5] # проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Удалим мусорные (служебые) символы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'freemsg hey there darling it s been week s now and no word back i d like some fun you up for it still tb ok xxx std chgs to send to rcv'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages_words = [re.sub('[\\W_\\d]+',' ', mess) for mess in messages_lower_case]\n",
    "messages_words[5] # проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Удалим стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сначала разделим все на слова\n",
    "messages_splitted = [mess.split() for mess in messages_words]\n",
    "len(messages_splitted[5]) # проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords_set = set(stopwords.words('english'))\n",
    "mess_without_sw = [[word for word in mess if word not in stopwords_set] for mess in messages_splitted]\n",
    "len(mess_without_sw[5]) # проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Приведем все слова к нормальной форме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['freemsg',\n",
       " 'hey',\n",
       " 'darling',\n",
       " 'week',\n",
       " 'word',\n",
       " 'back',\n",
       " 'like',\n",
       " 'fun',\n",
       " 'still',\n",
       " 'tb',\n",
       " 'ok',\n",
       " 'xxx',\n",
       " 'std',\n",
       " 'chgs',\n",
       " 'send',\n",
       " 'rcv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_mess = [[wordnet_lemmatizer.lemmatize(word) for word in mess] for mess in mess_without_sw]\n",
    "lemmatized_mess[5] # проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'freemsg hey darling week word back like fun still tb ok xxx std chgs send rcv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_mess_joined = [' '.join(mess) for mess in lemmatized_mess]\n",
    "lemmatized_mess_joined[5] # проверка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Преобразуем все сообщения в вектора TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(lemmatized_mess_joined)\n",
    "names = tfidf.get_feature_names()\n",
    "tfidf_matrix = pd.DataFrame(tfidf_matrix.toarray(), columns=names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Разделяем данные на тестовые и тренировочные в соотношении 30/70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала определим в исходном датасете class_message\n",
    "data_changed = data_spam.copy()\n",
    "\n",
    "def add_class_message(row):\n",
    "    if row.Category == 'ham':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "data_changed['class_message'] = data_changed.apply(add_class_message, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_message</th>\n",
       "      <th>aa</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaniye</th>\n",
       "      <th>aaooooright</th>\n",
       "      <th>aathi</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abeg</th>\n",
       "      <th>...</th>\n",
       "      <th>zf</th>\n",
       "      <th>zhong</th>\n",
       "      <th>zindgi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zogtorius</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>zyada</th>\n",
       "      <th>èn</th>\n",
       "      <th>〨ud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class_message   aa  aah  aaniye  aaooooright  aathi   ab  abbey  abdomen  \\\n",
       "0              0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   \n",
       "1              0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   \n",
       "2              1  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   \n",
       "3              0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   \n",
       "4              0  0.0  0.0     0.0          0.0    0.0  0.0    0.0      0.0   \n",
       "\n",
       "   abeg  ...   zf  zhong  zindgi  zoe  zogtorius  zoom  zouk  zyada   èn  〨ud  \n",
       "0   0.0  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "1   0.0  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "2   0.0  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "3   0.0  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "4   0.0  ...  0.0    0.0     0.0  0.0        0.0   0.0   0.0    0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 7100 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соединим матрицу со столбцом спам / не спам, используя столбец class_message в data_changed\n",
    "data_concat = pd.concat([data_changed['class_message'], tfidf_matrix], axis=1, sort=False)\n",
    "data_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разделяем данные на выборку для обучения и тестирования\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_concat.iloc[:,1:], data_concat.class_message, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Построим модель логистической регрессии, оценим ее точность на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9599282296650717"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# определяем точность прогноза \n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Опишем результаты при помощи confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1445,    3],\n",
       "       [  64,  160]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      1448\n",
      "           1       0.98      0.71      0.83       224\n",
      "\n",
      "    accuracy                           0.96      1672\n",
      "   macro avg       0.97      0.86      0.90      1672\n",
      "weighted avg       0.96      0.96      0.96      1672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Classification Report : ')\n",
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вывод: всего было 1445 истинных положительных результатов, 3 ложных положительных результатов, 64 ложных отрицательных и 160 истинных отрицательных.\n",
    "    Precision (0.98) говорит нам, что в 98% случаев модель распознает спам.\n",
    "    Recall (0.71) говорит нам, что в 29% случаев нормальное письмо попадет в спам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Построим датафрейм, который будет содержать все исходные тексты сообщений, классифицированные неправильно (с указанием фактического и предсказанного)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Predictions\n",
       "2952            1\n",
       "881             0\n",
       "1961            0\n",
       "3864            0\n",
       "2575            0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# соотнесем предсказания с индексами исходного датасета, сохраняя при этом только те, что классифицированы неправильно\n",
    "data_pred = pd.DataFrame(y_test)\n",
    "data_pred['Predictions'] = pd.Series(y_pred, index=data_pred.index)\n",
    "data_pred_ = data_pred[data_pred.class_message != data_pred.Predictions]\n",
    "del data_pred_['class_message']\n",
    "data_pred_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Message</th>\n",
       "      <th>Category</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Your free ringtone is waiting to be collected....</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Want 2 get laid tonight? Want real Dogging loc...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Are you unique enough? Find out from 30th Augu...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Will u meet ur dream partner soon? Is ur caree...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>SMS. ac Blind Date 4U!: Rodds1 is 21/m from Ab...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>TheMob&gt; Check out our newest selection of cont...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Call Germany for only 1 pence per minute! Call...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>100 dating service cal;l 09064012103 box334sk38ch</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Are you free now?can i call now?</td>\n",
       "      <td>ham</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>#ERROR!</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>Boltblue tones for 150p Reply POLY# or MONO# e...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>Email AlertFrom: Jeri StewartSize: 2KBSubject:...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Do you realize that in about 40 years, we'll h...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>You have an important customer service announc...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Urgent Ur £500 guaranteed award is still uncla...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>Talk sexy!! Make new friends or fall in love i...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>Reminder: You have not downloaded the content ...</td>\n",
       "      <td>spam</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Message Category Predictions\n",
       "15   XXXMobileMovieClub: To use your credit, click ...     spam         ham\n",
       "19   England v Macedonia - dont miss the goals/team...     spam         ham\n",
       "68   Did you hear about the new \"Divorce Barbie\"? I...     spam         ham\n",
       "95   Your free ringtone is waiting to be collected....     spam         ham\n",
       "135  Want 2 get laid tonight? Want real Dogging loc...     spam         ham\n",
       "191  Are you unique enough? Find out from 30th Augu...     spam         ham\n",
       "227  Will u meet ur dream partner soon? Is ur caree...     spam         ham\n",
       "305  SMS. ac Blind Date 4U!: Rodds1 is 21/m from Ab...     spam         ham\n",
       "309  TheMob> Check out our newest selection of cont...     spam         ham\n",
       "333  Call Germany for only 1 pence per minute! Call...     spam         ham\n",
       "415  100 dating service cal;l 09064012103 box334sk38ch     spam         ham\n",
       "495                   Are you free now?can i call now?      ham        spam\n",
       "505                                            #ERROR!     spam         ham\n",
       "517  Boltblue tones for 150p Reply POLY# or MONO# e...     spam         ham\n",
       "731  Email AlertFrom: Jeri StewartSize: 2KBSubject:...     spam         ham\n",
       "751  Do you realize that in about 40 years, we'll h...     spam         ham\n",
       "752  You have an important customer service announc...     spam         ham\n",
       "763  Urgent Ur £500 guaranteed award is still uncla...     spam         ham\n",
       "856  Talk sexy!! Make new friends or fall in love i...     spam         ham\n",
       "881  Reminder: You have not downloaded the content ...     spam         ham"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_final = pd.merge(data_changed, data_pred_, left_index=True, right_index=True)\n",
    "del data_final['class_message']\n",
    "data_final = data_final[['Message', 'Category', 'Predictions']]\n",
    "\n",
    "def return_category(row):\n",
    "    if row['Predictions'] == 0:\n",
    "        return 'ham'\n",
    "    else:\n",
    "        return 'spam'\n",
    "\n",
    "data_final['Predictions'] = data_final.apply(return_category, axis=1)\n",
    "data_final.head(20) # итоговый датафрейм"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
